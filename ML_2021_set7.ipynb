{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to Modern Data Science Problems (probelms till 22.01 and 5.02)\n",
    "disclaimer: none optional problems presented here!\n",
    "I dedicated a separated notebook to them.\n",
    "\n",
    "*by Mateusz Kmieć*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#standard imports \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 49\n",
    "Discuss the performance of different classification models (A-E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](roc.png)\n",
    "Figure.1:   source: http://koza.if.uj.edu.pl/~krzemien/machine_learning2021/materials/problems_till_lecture_10.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The best performance is for D since TPR=1 and FPR is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. As far as A, B, C and E the usefulness of the chosen classifier is dependent on the classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For A we have very low FPR and fairly high TPR. Such classifier could be useful for detection of crime. We don't want to falsely accuse somebody of crime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. As fas as B is concerned It has quite high TPR and less than satisfactory FPR. It might be useful for COVID detection. We have high TPR at the expense of FPR. In the case of COVID detection we are not as much concerned with high FPR results detection as we are with low TPR. It is better to be careful than sorry. At worst people are classified as ill and have to quarantine for two weeks. In the opposite case we are at risk of causing accelerated spread of the deadly disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. As for C it lies almost on the random guessing line and so we have nearly no predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. On the one hand for E we have a very high FPR and low TPR and so it is the worst classifier, it is even worse than C. On the other hand we could invert the condition of this classifier and obtain a classifier with a decent predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 50\n",
    "We have k = 10 classes and a binary model. How many comparisons do we need to perform using all-vs-one approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform 10 comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53\n",
    "For which method, there is a guarantee that it will converge to the global minimum. Justify your choice if possible:\n",
    "* GD\n",
    "* SGD\n",
    "* ADAM\n",
    "* Newton’s method\n",
    "* All of them\n",
    "* None of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of them. We cannot even guarantee their convergence and when they converge it is a convergence to the local minimum. Newton-method usually converges much faster than GD. Newton-method invlolves inverting hessian. For high dimensions Hessian might be too expensive to \n",
    "invert. Although for large sets of data the best convergence is usually observed for ADAM, the best generalisation power is attributed to SGD-like methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 54\n",
    "We use a large dataset with a multidimensional features space. Which method would be probably appropriate to use? Justify your choice if possible\n",
    "* GD\n",
    "* SGD\n",
    "* ADAM\n",
    "* Newton’s method\n",
    "* All of them\n",
    "* None of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton-method usually converges much faster than GD. Newton-method invlolves inverting hessian. For high dimensions Hessian might be too expensive to \n",
    "invert. GD might turn out to be too computationally expensive for large datasets that is why  for large sets of data we should use SGD or Adam. At some point Adam was a recommended over SGD (lower training errors, faster convergence).\n",
    "This recommendation is questioned by several studies (SGD-like methods generalize better in \n",
    "many cases than Adam-like methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 55\n",
    "Which of the statements are true?\n",
    "* SGD is guaranteed to decrease the cost function in every iteration\n",
    "* SGD uses small subsample (or one sample) to update the parameters\n",
    "* When using SGD we don't need to randomize the data sample\n",
    "* When using GD we don't need to randomize the data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 56\n",
    "Which of the statements are true?\n",
    "* GD with a very small learning rate can be ineffective in a sense that it would take a lot of time to find the solution (to converge).\n",
    "* SGD with a very large learning rate can be ineffective in a sense that it would take a lot of time to find the solution (to converge).\n",
    "* If we choose small enough learning rate, then we are guaranteed to converge to the same solution independent on the initial values.\n",
    "* When the value of learning rate is too large then we can \"overshoot\" the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 57\n",
    "Which of the statements are true?\n",
    "\n",
    "1. Newton's method uses information about the Hessian. True (It uses both gradient and hessian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. GD uses information about the Hessian. False (It uses only gradient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Newton's method in many cases can converge faster than GD but it can be very expensive for multidimensional data.  True (Inverting hessian has high computational cost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 58\n",
    "\n",
    "Consider document classifier with k classes. Every document is described by at least p\n",
    "ordered words (features). Every word belongs to the dictionary of m values. How many\n",
    "parameters we must estimate for:\n",
    "\n",
    "• Bayes classifier\n",
    "\n",
    "• Naive Bayes classifier\n",
    "\n",
    "• Naive Bayes classifier with the bag-of-model assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 59\n",
    "\n",
    "Consider Laplacian smoothing for $k=2$. Discuss cases of:\n",
    "    \n",
    "• $\\alpha = 0.5$\n",
    "\n",
    "• $\\alpha = 1$\n",
    "\n",
    "• $\\alpha = 0$\n",
    "\n",
    "with respect to freqency prediction #$x_{i}$/#$y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
