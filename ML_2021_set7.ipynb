{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to Modern Data Science Problems (probelms till 22.01)\n",
    "\n",
    "*by Mateusz Kmieć*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#standard imports \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 49\n",
    "Discuss the performance of different classification models (A-E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](roc.png)\n",
    "Figure.1:   source: http://koza.if.uj.edu.pl/~krzemien/machine_learning2021/materials/problems_till_lecture_10.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.The best performance is for D since TPR=1 and FPR is 0.\n",
    "\n",
    "2.As far as A, B, C and E the usefulness of the chosen classifier is dependent on the classification problem.\n",
    "\n",
    "3.For A we have very low FPR and fairly high TPR. Such classifier could be useful for detection of crime. We don't want to falsely accuse somebody of crime. \n",
    "\n",
    "4.As fas as B is concerned It has quite high TPR and less than satisfactory FPR. It might be useful for COVID detection. We have high TPR at the expense of FPR. In the case of COVID detection we are not as much concerned with high FPR results detection as we are with low TPR. It is better to be careful than sorry. At worst people are classified as ill and have to quarantine for two weeks. In the opposite case we are at risk of causing accelerated spread of the deadly disease.\n",
    "\n",
    "\n",
    "5.As for C it lies almost on the random guessing line and so we have nearly no predictive power.\n",
    "\n",
    "6.On the one hand for E we have a very high FPR and low TPR and so it is the worst classifier, it is even worse than C. On the other hand we could invert the condition of this classifier and obtain a classifier with a decent predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 50\n",
    "We have k = 10 classes and a binary model. How many comparisons do we need to perform using all-vs-one approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform 10 comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53\n",
    "For which method, there is a guarantee that it will converge to the global minimum. Justify your choice if possible:\n",
    "* GD\n",
    "* SGD\n",
    "* ADAM\n",
    "* Newton’s method\n",
    "* All of them\n",
    "* None of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 54\n",
    "We use a large dataset with a multidimensional features space. Which method would be probably appropriate to use? Justify your choice if possible\n",
    "* GD\n",
    "* SGD\n",
    "* ADAM\n",
    "* Newton’s method\n",
    "* All of them\n",
    "* None of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 55\n",
    "Which of the statements are true?\n",
    "* SGD is guaranteed to decrease the cost function in every iteration\n",
    "* SGD uses small subsample (or one sample) to update the parameters\n",
    "* When using SGD we don't need to randomize the data sample\n",
    "* When using GD we don't need to randomize the data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 56\n",
    "Which of the statements are true?\n",
    "* GD with a very small learning rate can be ineffective in a sense that it would take a lot of time to find the solution (to converge).\n",
    "* SGD with a very large learning rate can be ineffective in a sense that it would take a lot of time to find the solution (to converge).\n",
    "* If we choose small enough learning rate, then we are guaranteed to converge to the same solution independent on the initial values.\n",
    "* When the value of learning rate is too large then we can \"overshoot\" the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 57\n",
    "Which of the statements are true?\n",
    "* Newton's method uses information about the Hessian.\n",
    "* GD uses information about the Hessian.\n",
    "* Newton' method in many cases can converge faster than GD but it can be very expensive for multidimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
